{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provider Comparison\n",
    "\n",
    "This notebook compares different LLM providers side-by-side to help you choose the right one for your use case.\n",
    "\n",
    "## Providers Compared\n",
    "\n",
    "| Provider | Strengths | Best For |\n",
    "|----------|-----------|----------|\n",
    "| **OpenAI** | Quality, features | General use, function calling |\n",
    "| **Anthropic** | Reasoning, instructions | Complex analysis, writing |\n",
    "| **Gemini** | Free tier, multimodal | Experimentation, images |\n",
    "| **Groq** | Speed | Real-time applications |\n",
    "| **Ollama** | Privacy, cost | Local/offline use |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install the package and configure API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the package\n",
    "!pip install -q git+https://github.com/deepakdeo/python-llm-playbook.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup API Keys from Colab Secrets\n",
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# Add your keys in the Secrets pane (ðŸ”‘ icon in left sidebar)\n",
    "keys = ['OPENAI_API_KEY', 'ANTHROPIC_API_KEY', 'GOOGLE_API_KEY', 'GROQ_API_KEY']\n",
    "\n",
    "for key in keys:\n",
    "    try:\n",
    "        os.environ[key] = userdata.get(key)\n",
    "        print(f\"{key}: âœ“\")\n",
    "    except:\n",
    "        print(f\"{key}: âœ— (not found)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from llm_playbook import OpenAIClient, AnthropicClient, GeminiClient, GroqClient\n",
    "\n",
    "# Initialize clients\n",
    "providers = {}\n",
    "\n",
    "try:\n",
    "    providers['OpenAI'] = OpenAIClient()\n",
    "    print(\"OpenAI: Ready\")\n",
    "except Exception as e:\n",
    "    print(f\"OpenAI: Failed - {e}\")\n",
    "\n",
    "try:\n",
    "    providers['Anthropic'] = AnthropicClient()\n",
    "    print(\"Anthropic: Ready\")\n",
    "except Exception as e:\n",
    "    print(f\"Anthropic: Failed - {e}\")\n",
    "\n",
    "try:\n",
    "    providers['Gemini'] = GeminiClient()\n",
    "    print(\"Gemini: Ready\")\n",
    "except Exception as e:\n",
    "    print(f\"Gemini: Failed - {e}\")\n",
    "\n",
    "try:\n",
    "    providers['Groq'] = GroqClient()\n",
    "    print(\"Groq: Ready\")\n",
    "except Exception as e:\n",
    "    print(f\"Groq: Failed - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Same Prompt, Different Providers\n",
    "\n",
    "Let's send the same prompt to all providers and compare responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain recursion in one sentence.\"\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, client in providers.items():\n",
    "    try:\n",
    "        response = client.chat(prompt)\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{name}: Error - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Speed Comparison\n",
    "\n",
    "Compare response times across providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is Python? Answer in exactly 2 sentences.\"\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "times = {}\n",
    "\n",
    "for name, client in providers.items():\n",
    "    try:\n",
    "        start = time.time()\n",
    "        response = client.chat(prompt)\n",
    "        elapsed = time.time() - start\n",
    "        times[name] = elapsed\n",
    "        print(f\"\\n{name} ({elapsed:.2f}s):\")\n",
    "        print(f\"  {response[:150]}...\" if len(response) > 150 else f\"  {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{name}: Error - {e}\")\n",
    "\n",
    "# Show ranking\n",
    "if times:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Speed Ranking (fastest first):\")\n",
    "    for i, (name, t) in enumerate(sorted(times.items(), key=lambda x: x[1]), 1):\n",
    "        print(f\"  {i}. {name}: {t:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Following Instructions\n",
    "\n",
    "Test how well each provider follows specific formatting instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"List exactly 3 programming languages. Respond only in JSON format, no markdown.\"\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, client in providers.items():\n",
    "    try:\n",
    "        response = client.chat(prompt, temperature=0.0)\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{name}: Error - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creative Writing\n",
    "\n",
    "Compare creative output with higher temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a haiku about artificial intelligence.\"\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, client in providers.items():\n",
    "    try:\n",
    "        response = client.chat(prompt, temperature=1.0)\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{name}: Error - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. System Prompt Adherence\n",
    "\n",
    "Test how well providers follow system prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a pirate. Always respond in pirate speak with 'Arrr' and nautical terms.\"\n",
    "user_prompt = \"Tell me about the weather today.\"\n",
    "\n",
    "print(f\"System: {system_prompt}\")\n",
    "print(f\"User: {user_prompt}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, client in providers.items():\n",
    "    try:\n",
    "        response = client.chat(user_prompt, system_prompt=system_prompt)\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{name}: Error - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Reasoning Task\n",
    "\n",
    "Compare reasoning capabilities with a logic puzzle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"If all roses are flowers, and some flowers fade quickly, \n",
    "can we conclude that some roses fade quickly? Explain briefly.\"\"\"\n",
    "\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, client in providers.items():\n",
    "    try:\n",
    "        response = client.chat(prompt, temperature=0.0, max_tokens=150)\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{name}: Error - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. When to Use Each Provider\n",
    "\n",
    "Based on the comparisons above, here's a guide:\n",
    "\n",
    "### OpenAI (GPT-4o, GPT-4o-mini)\n",
    "**Best for:**\n",
    "- General-purpose tasks\n",
    "- Function calling and structured outputs\n",
    "- When you need reliability and consistency\n",
    "\n",
    "### Anthropic (Claude)\n",
    "**Best for:**\n",
    "- Complex reasoning tasks\n",
    "- Following detailed instructions\n",
    "- Long-form content and analysis\n",
    "- When accuracy matters most\n",
    "\n",
    "### Google Gemini\n",
    "**Best for:**\n",
    "- Budget-conscious development (generous free tier)\n",
    "- Multimodal tasks (images, video, audio)\n",
    "- Google ecosystem integration\n",
    "- Experimentation and prototyping\n",
    "\n",
    "### Groq\n",
    "**Best for:**\n",
    "- Real-time applications\n",
    "- High-throughput processing\n",
    "- When speed is critical\n",
    "- Using open-source models fast\n",
    "\n",
    "### Ollama (Local)\n",
    "**Best for:**\n",
    "- Privacy-sensitive data\n",
    "- Offline use\n",
    "- Avoiding API costs\n",
    "- Development and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Pricing Comparison (Approximate)\n",
    "\n",
    "| Provider | Model | Input (per 1M tokens) | Output (per 1M tokens) |\n",
    "|----------|-------|----------------------|------------------------|\n",
    "| OpenAI | GPT-4o-mini | $0.15 | $0.60 |\n",
    "| OpenAI | GPT-4o | $2.50 | $10.00 |\n",
    "| Anthropic | Claude 3 Haiku | $0.25 | $1.25 |\n",
    "| Anthropic | Claude Sonnet | $3.00 | $15.00 |\n",
    "| Gemini | Flash | Free tier / $0.075 | Free tier / $0.30 |\n",
    "| Gemini | Pro | $1.25 | $5.00 |\n",
    "| Groq | Llama 3.3 70B | Free tier | Free tier |\n",
    "| Ollama | Any | Free (local) | Free (local) |\n",
    "\n",
    "*Prices subject to change. Check provider websites for current pricing.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key takeaways:\n",
    "\n",
    "1. **No single best provider** - Each has strengths for different use cases\n",
    "2. **Groq is fastest** - Often 5-10x faster than others\n",
    "3. **Claude excels at reasoning** - Best for complex instructions\n",
    "4. **Gemini is most affordable** - Generous free tier\n",
    "5. **Ollama is free** - But requires local hardware\n",
    "6. **OpenAI is most balanced** - Good at everything\n",
    "\n",
    "## Tips for Choosing\n",
    "\n",
    "1. **Start with Gemini** for free experimentation\n",
    "2. **Use Groq** for real-time applications\n",
    "3. **Use Claude** for complex analysis and writing\n",
    "4. **Use OpenAI** for production reliability\n",
    "5. **Use Ollama** for privacy or offline needs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
